<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Genai on Armur</title>
    <link>https://armur.ai/blogs/tags/genai/</link>
    <description>Recent content in Genai on Armur</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 29 Sep 2024 18:31:22 +0530</lastBuildDate>
    <atom:link href="https://armur.ai/blogs/tags/genai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Securing AI-Generated Code</title>
      <link>https://armur.ai/blogs/posts/securing_ai_generated_code/</link>
      <pubDate>Sun, 29 Sep 2024 18:31:22 +0530</pubDate>
      <guid>https://armur.ai/blogs/posts/securing_ai_generated_code/</guid>
      <description>AI-generated code has transformed software development by automating repetitive tasks, accelerating workflows, and significantly boosting productivity. However, similar to human-written code, it introduces unique security risks that cannot be overlooked. As organizations increasingly integrate AI tools such as ChatGPT and GitHub Copilot into their development pipelines, securing AI-generated code becomes a critical priority. Vulnerabilities such as improper input handling, use of insecure third-party libraries, and susceptibility to adversarial attacks require careful attention and mitigation.</description>
    </item>
  </channel>
</rss>
